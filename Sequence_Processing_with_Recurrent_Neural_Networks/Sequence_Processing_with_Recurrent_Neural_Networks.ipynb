{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequence Processing with Recurrent Neural Networks\n",
    "\n",
    "So far, we have seen how word vectors can be constructed from corpus statistics, and how they can be utilized to infer latent semantic content either in isolation (e.g. genders from names) or in relation to one another (e.g. similarities and analogies). \n",
    "\n",
    "For tasks involving larger linguistic units such as phrases, sentences and dialogues, we need machinery capable of processing _sequences_ or _structures_ of words.\n",
    "\n",
    "Recurrent Neural Networks are an example of such machinery; for this assignment, you will construct a recurrent neural network that annotates each word of a sentence with a linguistically informative marker. In the simple case (and in this assignment), these markers will be POS tags. However, they can also be morphosyntactic informative [categories](https://en.wikipedia.org/wiki/Combinatory_categorial_grammar) (supertags).\n",
    "\n",
    "In both cases, the task is a case of sequence labeling.  A good reference point is Jurafsky and Martin [Chapter 9](https://web.stanford.edu/~jurafsky/slp3/9.pdf). For a fuller view of the picture, a good reference point is Alex Graves' [dissertation](https://www.cs.toronto.edu/~graves/preprint.pdf).\n",
    "\n",
    "We will take a gradual approach, first inspecting recurrent neural networks, then moving on to data processing using high-grade word vectors before finally moving to the problem at hand. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recurrent Neural Networks\n",
    "Recurrent Neural Networks are a particularly interesting class of neural networks. Unlike standard fully-connected networks, which accept a fixed-size input and produce a fixed-size output over a predefined number of computational steps (i.e. network layers), RNNs instead operate on sequences of vectors. \n",
    "\n",
    "Computationally, feedforward networks may be seen as a trainable (but parametrically fixed) function, whereas RNNs act as continuous, stateful programs operating on sequences of inputs. \n",
    "Cognitively, this may be viewed as enhancing our system's perceptive and computational abilities with a notion of memory.\n",
    "In the general case, this statefulness is captured by an intermediate hidden vector which is adjusted throughout the computation, affected by both the immediately previous version of itself __and__ the current input.\n",
    "\n",
    "RNNs are nowadays established as the core machinery of neural sequence processing. \n",
    "\n",
    "A simple recurrent network (SRN or Elman network) is described by the equations:\n",
    "* $h_t = \\theta_h (W_h x_t + U_h h_{t-1} + b_h ) $\n",
    "* $y_t = \\theta_y (W_y h_t + b_y) $\n",
    "\n",
    "where (at timestep $t$) $x_t$, $h_t$, $y_t$ are the network's input, hidden and output representations respectively, $\\theta_h$, $\\theta_y$ its hidden and output activation functions, and $W_h$, $U_h$, $b_h$, $W_y$, $b_y$ parametric tensors to be learned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import FloatTensor, LongTensor\n",
    "from typing import Tuple, List, Callable, Optional"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assignment 2.0: Our own SRN\n",
    "Let's make our own simple recurrent network from scratch, to get an idea of its inner workings. To make our life just a bit simpler, we will use `torch.nn.Linear` to model the internal transformations.\n",
    "\n",
    "Complete the `mySRN` class, which is initialized with the input $d_i$, hidden $d_h$ and output $d_o$ dimensionalities, as well as two non-linear functions $\\theta_h$ and $\\theta_y$, and constructs a SRN implementing three `torch.nn.Linear` layers:\n",
    "1. `x_to_h`: a layer that takes $x_t$ and produces $W_h x_t$\n",
    "2. `h_to_h`: a layer that takes $h_{t-1}$ and produces $U_h h_{t-1} + b_h$\n",
    "3. `h_to_y`: a layer that takes $h_t$ and produces $W_y h_t + b_y$\n",
    "\n",
    "Implement the function `step` that performs a computational step, accepting $x_t$ and $h_{t-1}$ and producing $h_t$ and $y_t$.\n",
    "\n",
    "Implement the function forward that accepts a List of inputs $X$, an initial hidden vector $h_{-1}$ and iteratively applies `step` until the input sequence is exhausted, returning a List of outputs $Y$ (of the same length as $X$).\n",
    "\n",
    "_Hint_: Note that `x_to_h` does not have a bias term $b$, since we will incorporate it into `h_to_h`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class mySRN(torch.nn.Module):\n",
    "    def __init__(self, input_dim: int, hidden_dim: int, output_dim: int, \n",
    "                 hidden_activation: Callable[[FloatTensor], FloatTensor],\n",
    "                 output_activation: Callable[[FloatTensor], FloatTensor],\n",
    "                 device: str):\n",
    "        super(mySRN, self).__init__()\n",
    "        self.hidden_activation = hidden_activation\n",
    "        self.output_activation = output_activation\n",
    "        self.device = device\n",
    "        \n",
    "        self.x_to_h = torch.nn.Linear(input_dim, hidden_dim, bias=False)\n",
    "        self.h_to_h = torch.nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.h_to_y = torch.nn.Linear(hidden_dim, output_dim)\n",
    "        \n",
    "    def step(self, x: FloatTensor, h: FloatTensor) -> Tuple[FloatTensor, FloatTensor]:\n",
    "        ht = self.hidden_activation(self.x_to_h(x) + self.h_to_h(h))\n",
    "        yt = self.output_activation(self.h_to_y(ht))\n",
    "        return ht, yt\n",
    "        \n",
    "    def forward(self, X: List[FloatTensor], h: FloatTensor) -> List[FloatTensor]:\n",
    "        outputs = []\n",
    "        ht = h\n",
    "        for item in X:\n",
    "            ht, output = self.step(item, ht)\n",
    "            outputs.append(output)\n",
    "        return outputs\n",
    "\n",
    "f = mySRN(3,3,1, hidden_activation=torch.nn.Tanh(), output_activation=torch.nn.Sigmoid(), device='cpu')\n",
    "X = (torch.rand(3), torch.rand(3), torch.rand(3))\n",
    "h = torch.rand(3)\n",
    "y = f(X,h)\n",
    "# print(y)   used to check the network effectively worked"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In practice, we do not need to write our own functions for common RNN architectures. \n",
    "Torch already provides the [necessary abstractions](https://pytorch.org/docs/stable/nn.html#recurrent-layers).\n",
    "\n",
    "The [RNN](https://pytorch.org/docs/stable/nn.html#rnn) wrapper implements highly optimized forward routines to compute the hidden representations of a full input sequence.\n",
    "\n",
    "Some pointers:\n",
    "* Unlike our naive implementation, RNN accepts a 3-dimensional tensor of shape (seq_len, batch_shape, input_dim) rather than a list of 2-dimensional tensors\n",
    "* If no initial hidden state is provided, it defaults to a zero tensor\n",
    "* The class produces just the RNN hidden states; it is up to us to define the `h_to_y` transformation on top of them\n",
    "* The non-linearity argument is a string; our only two choices are either `'tanh'` or `'relu'` (shorthands for `torch.nn.Tanh` and `torch.nn.ReLU` respectively)\n",
    "\n",
    "Read the documentation (!) for further details.\n",
    "\n",
    "A brief example is given below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 32, 48])\n"
     ]
    }
   ],
   "source": [
    "rnn = torch.nn.RNN(input_size=16, hidden_size=48, nonlinearity='tanh')\n",
    "X = torch.rand(10, 32, 16)\n",
    "h, _ = rnn(X)\n",
    "print(h.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, for a random input tensor of shape (seq_len, batch_size, input_dim), we get back an output tensor of shape (seq_len, batch_size, hidden_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "del mySRN, rnn, X, h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assignment 2.1: A faster version of the SRN\n",
    "Now let's wrap an `RNN` into a custom module `myFastSRN` that implements it aside the `h_to_y` transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class fastSRN(torch.nn.Module):\n",
    "    def __init__(self, input_dim: int, hidden_dim: int, output_dim: int, \n",
    "                 hidden_activation: str,\n",
    "                 output_activation: Callable[[FloatTensor], FloatTensor],\n",
    "                 device: str):\n",
    "        super(fastSRN, self).__init__()\n",
    "        self.output_activation = output_activation\n",
    "        self.hidden = torch.nn.RNN(input_size=input_dim, hidden_size=hidden_dim, nonlinearity=hidden_activation)\n",
    "        self.h_to_y = torch.nn.Linear(hidden_dim, output_dim)\n",
    "        \n",
    "        \n",
    "    def forward(self, X:FloatTensor, h: Optional[FloatTensor]=None) -> FloatTensor:\n",
    "        return self.output_activation(self.h_to_y(self.hidden(X, h)[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see our new implementation in action. \n",
    "\n",
    "Initialize a random input tensor $X$ that would correspond to 32 sequences,  each of length 10, with each item having 16 features, and a `fastSRN` fit to process it, producing 42-dimensional hidden states and 2-dimension output vectors for each sequence item.\n",
    "\n",
    "Run the SRN on the tensor and make sure the output shape is as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 32, 2])\n"
     ]
    }
   ],
   "source": [
    "f = fastSRN(16, 42, 2, hidden_activation='tanh', output_activation=torch.nn.Sigmoid(), device='cpu')\n",
    "X = torch.rand(10,32,16)\n",
    "print(f(X).shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hopefully everything should be in order.\n",
    "\n",
    "You may have noticed a minor complication: in order to utilize batching, we need our input sequences to be of the same length.\n",
    "\n",
    "This however is very rarely the case in practice. A common trick against this problem is _padding_; that is, appending zero tensors to all input sequences shorter than the maximum in-batch length to make them all equally long.\n",
    "\n",
    "As usual, torch already does the hard work for us via [pad_sequence](https://pytorch.org/docs/stable/nn.html?highlight=pad%20_sequence#torch.nn.utils.rnn.pad_sequence). Given a list of $N$ 2-dimensional tensors, each of shape (seq_len$_n$, input_dim), it will construct a 3-d tensor of shape ($max_{n \\in N}${seq_len$_n$}, N, input_dim).\n",
    "\n",
    "An example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([7, 3, 16])\n"
     ]
    }
   ],
   "source": [
    "x_1 = torch.rand(1, 16)  # a sequence of 1, 16-dimensional item\n",
    "x_2 = torch.rand(7, 16)  # a sequence of 7, 16-dimensional items\n",
    "x_3 = torch.rand(5, 16)  # a sequence of 5, 16-dimensional items\n",
    "\n",
    "X = torch.nn.utils.rnn.pad_sequence([x_1, x_2, x_3])  \n",
    "\n",
    "# Can you guess what the shape of X is?\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "del x_1, x_2, x_3, X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pretrained Word Embeddings\n",
    "Moving on-- last assignment, we saw how to train our own word embeddings using a miniature toy corpus. Now, we will see how to easily employ high-quality pretrained word vectors and, later on, how to utilize them for further downstream tasks.\n",
    "\n",
    "We are going to use [spaCy](https://spacy.io/). SpaCy is a high-level NLP library that provides a ton of useful functionalities, but we will only focus on its pretrained embeddings for this assignment.\n",
    "\n",
    "Before proceeding, [install spacy](https://spacy.io/usage) using your python package manager (e.g. `pip install spacy`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SpaCy comes with a lot of different-size models for different languages. \n",
    "\n",
    "We will need to download the small english model for the exercises to follow. You can either do it on a new terminal window (optimal, if you are running this assignment through a virtual environment) or by simply running the magic command below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Python was not found but can be installed from the Microsoft Store: https://go.microsoft.com/fwlink?linkID=2082640\n"
     ]
    }
   ],
   "source": [
    "!python3 -m spacy download en_core_web_lg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After having downloaded the model, we can load it as follows (you may need to restart your notebook after the download is complete):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_lg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then use the loaded model to process a sentence and obtain its word vectors, a List of 300-dimensional numpy arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have 7 vectors..\n",
      "..each of shape (300,)\n"
     ]
    }
   ],
   "source": [
    "doc = nlp('this is a sentence of 7 words')  # the processed sentence\n",
    "vectors = list(map(lambda x: x.vector, doc))  # its vectors\n",
    "print('We have {} vectors..'.format(len(vectors)))\n",
    "print('..each of shape {}'.format(vectors[0].shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then finally convert them into torch tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([7, 300])\n"
     ]
    }
   ],
   "source": [
    "torch_vectors = torch.tensor(vectors)\n",
    "print(torch_vectors.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or, in the case of multiple sentences:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example sentences\n",
    "sentences = ['This is a sentence', 'This is another sentence.']\n",
    "\n",
    "# Parallel processing with spacy\n",
    "docs = list(map(nlp, sentences))\n",
    "\n",
    "# Convert each processed sentence into a list of vectors\n",
    "vectors = map(lambda doc: [word.vector for word in doc], docs)\n",
    "\n",
    "# Convert each list of vectors into a 2-d torch tensor\n",
    "tensors = list(map(lambda sentence_vectors: torch.tensor(sentence_vectors), vectors))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## POS Tagging\n",
    "Given our pretrained embeddings, we may represent sentences as _sequences of vectors_, which is exactly the format expected by an RNN.\n",
    "We will now try to train an SRN to iterate over a sentence and assign part of speech tags to each of its words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assignment 2.2: Why use an RNN?\n",
    "In the context of POS tagging, what is the advantage of using a recurrent network over a feedforward network that processes each word individually?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In natural language, the meaning of a word is not usually the same in all words, but can differ based on its context in a sentence. By looking at words in the sequence in which they occur in a sentence, the temporal relationships in this context can be taken into account. These relationships cannot be captured by a feedforward network, but can be captured by a recurrent network. This makes the use of a recurrent network more advantageous."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "First, let's load and inspect our datafiles.\n",
    "\n",
    "The pickle file contains three items:\n",
    "1. `sentences`: a List of strings (-sentences)\n",
    "1. `postags`: a List of Lists of strings (-POS tags)\n",
    "2. `pos_to_int`: a Dictionary from strings to ints (mapping each POS tag to a unique identifier)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('TRAIN.p', 'rb') as f:\n",
    "    sentences, postags, pos_to_int = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#same for the test set\n",
    "with open('TEST.p', 'rb') as f_test:\n",
    "    sentences_test, postags_test, pos_to_int_test = pickle.load(f_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let us take a moment to understand the data a bit more. \n",
    "The POS tags in this dataset are in the style of the Penn Treebank. Find the top 20 most common tags and plot a histogram of their frequencies. Find out what these tags mean linguisically! https://www.ling.upenn.edu/courses/Fall_2003/ling001/penn_treebank_pos.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "flattened = [val for sublist in postags for val in sublist if val != '.' and val != ',']\n",
    "most_freq = Counter(flattened)\n",
    "top_20_pairs = most_freq.most_common(20)\n",
    "top_20 = [i[0] for i in top_20_pairs]\n",
    "\n",
    "indices = np.arange(len(top_20))\n",
    "plt.bar(indices, [i[1] for i in top_20_pairs], color='r')\n",
    "plt.xticks(indices, top_20, rotation='vertical')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we need to convert our data to numeric form."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assignment 2.3: Tensorizing sentences\n",
    "Convert sentences to their tensor format, as done earlier (this may take a while). \n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Important!</b>\n",
    "Since the sentences are pre-tokenized (i.e. they are provided as sequences of words rather than strings), we need to change the processing call to ensure the output vectors are aligned with our tokenization.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = list(map(lambda sentence: \n",
    "                spacy.tokens.doc.Doc(nlp.vocab, words=sentence.split()), \n",
    "            sentences))\n",
    "\n",
    "doc_vectors = map(lambda doc: [word.vector for word in doc], docs)\n",
    "\n",
    "doc_tensors = list(map(lambda sentence_vectors: torch.tensor(sentence_vectors), doc_vectors))\n",
    "\n",
    "# We no longer need the docs and numpy array\n",
    "del doc_vectors, docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# same for the test set\n",
    "docs_test = list(map(lambda sentence: \n",
    "                spacy.tokens.doc.Doc(nlp.vocab, words=sentence), \n",
    "            sentences_test))\n",
    "\n",
    "doc_vectors_test = map(lambda doc: [word.vector for word in doc], docs_test)\n",
    "\n",
    "doc_tensors_test = list(map(lambda sentence_vectors: torch.tensor(sentence_vectors), doc_vectors_test))\n",
    "\n",
    "# We no longer need the docs and numpy array\n",
    "del doc_vectors_test, docs_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, we will use `pos_to_int` to convert the POS sequences into tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_numeric = list(map(lambda pos_sequence: [pos_to_int[pos] for pos in pos_sequence], postags))\n",
    "pos_tensors =  list(map(lambda pos_num_sequence: torch.tensor(pos_num_sequence), pos_numeric))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# same for the test set\n",
    "pos_tensors_test =  list(map(lambda pos_num_sequence: torch.tensor(pos_num_sequence), postags_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the first assignment, we saw how to split our dataset into a training and a validation set. \n",
    "\n",
    "Do the same here, splitting the sentences, postags and their corresponding tensors into a training and a validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "sentences_train, sentences_val, postags_train, postags_val, X_train, X_val, Y_train, Y_val \\\n",
    "    = train_test_split(sentences, postags, doc_tensors, pos_tensors, test_size=0.2)\n",
    "assert len(X_train) == len(Y_train) == len(sentences_train)\n",
    "assert len(X_val) == len(Y_val) == len(sentences_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = doc_tensors_test\n",
    "Y_test = pos_tensors_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, following along the first assignment, we will wrap our tensors into a `Dataset` and a `DataLoader`.\n",
    "\n",
    "Since our data are not Tensors but rather Lists of Tensors of uneven lengths, we need to write our own Dataset wrapper.\n",
    "The wrapper only needs to implement two functions; `__len__`, which expects no arguments and returns the number of samples in the dataset, and `__getitem__`, which accepts an index `idx` and returns the input-output pair `X[idx]`, `Y[idx]`.\n",
    "\n",
    "Similarly, the Dataloader needs to process the list of input-output pairs produced by the Dataset using `pad_sequence`, as seen earlier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assignment 2.4: Padding\n",
    "#### a) What is the advantage to applying padding on the batch rather than the entire dataset?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given that padding changes the sequences so they are all the same length as the longest sequence, doing this for the entire data set changes the lengths of all sequences to the length of the longest sequence of the overall data set. If this is a particularly large sequence, then a lot of space is unnecessarily used for the padding of the other sequences. When applying padding to batches, this extensive padding for the longest sequence will only be applied to that one batch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b) Fill in the code for `UnevenLengthDataset` class, implementing its two core functions.\n",
    "\n",
    "Then, complete the function `pad_batch` which takes a list of (x$_i$, y$_i$) pairs and produces the pair of their paddings: (X, Y).\n",
    "\n",
    "Given the two, the `DataLoader` object defined can iterate over the Dataset yielding uniform batches ready to be consumed by an RNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "\n",
    "class UnevenLengthDataset(Dataset):\n",
    "    def __init__(self, X: List[FloatTensor], Y: List[LongTensor]) -> None:\n",
    "        self.X = X\n",
    "        self.Y = Y\n",
    "        \n",
    "    def __len__(self) -> int:\n",
    "        return len(self.X)\n",
    "        \n",
    "    def __getitem__(self, idx: int) -> Tuple[FloatTensor, LongTensor]:\n",
    "        return (self.X[idx], self.Y[idx])\n",
    "    \n",
    "    \n",
    "def pad_batch(batch: List[Tuple[FloatTensor, LongTensor]]) -> Tuple[FloatTensor, LongTensor]:\n",
    "    padded_X = torch.nn.utils.rnn.pad_sequence([i[0] for i in batch], batch_first=False) #unsure if this should be true\n",
    "    padded_Y = torch.nn.utils.rnn.pad_sequence([i[1] for i in batch], batch_first=False) #unsure if this should be true\n",
    "    padded_pair = (padded_X, padded_Y)\n",
    "    return padded_pair\n",
    "                  \n",
    "train_dataset = UnevenLengthDataset(X_train, Y_train)\n",
    "train_dataloader = DataLoader(train_dataset, \n",
    "                              collate_fn=pad_batch,\n",
    "                              shuffle=True,\n",
    "                              batch_size=32)\n",
    "\n",
    "val_dataset = UnevenLengthDataset(X_val, Y_val)\n",
    "val_dataloader = DataLoader(val_dataset,\n",
    "                            collate_fn=pad_batch,\n",
    "                            shuffle=False,\n",
    "                            batch_size=32)\n",
    "\n",
    "test_dataset = UnevenLengthDataset(X_test, Y_test)\n",
    "test_dataloader = DataLoader(test_dataset,\n",
    "                            collate_fn=pad_batch,\n",
    "                            shuffle=False,\n",
    "                            batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What does a batch look like, shape-wise?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([54, 32, 300])\n",
      "torch.Size([54, 32])\n"
     ]
    }
   ],
   "source": [
    "for batch_x, batch_y in train_dataloader:\n",
    "    print(batch_x.shape)\n",
    "    print(batch_y.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far so good. On to the network.\n",
    "\n",
    "### Assignment 2.5: Utility Functions\n",
    "Remember how we defined our training and validation functions for the first assignment?\n",
    "\n",
    "You will need to do the same here.\n",
    "Note that while you can use the given code as a guideline, just copying it won't do the trick; unlike a feedforward net, a recurrent network produces a 3rd order output tensor, of shape (max_seq_len, batch_size, num_output_classes).\n",
    "\n",
    "Similarly, our target Y is a 2nd order tensor of shape (max_seq_len, batch_size).\n",
    "\n",
    "You will need to properly treat the extra dimensional of both the output and the target, since loss functions expect an order 2 output tensor and an order 1 target tensor. \n",
    "\n",
    "Complete the functions `train_batch`, `train_epoch`, `eval_batch` and `eval_epoch`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(predictions: LongTensor, truth: LongTensor, ignore_idx: int) -> Tuple[int, int]:\n",
    "    \"\"\"\n",
    "        Given a tensor containing the network's predictions and a tensor containing the true values, as well\n",
    "        as an output value to ignore (e.g. the padding value), computes and returns the total count of non-\n",
    "        ignored values as well the total count of correctly predicted values.\n",
    "        \n",
    "        predictions: The network's predictions.\n",
    "        truth: The true output labels.\n",
    "        ignore_idx: The output padding value, to be ignored in accuracy calculation.\n",
    "    \"\"\"\n",
    "    \n",
    "    correct_words = torch.ones(predictions.size())\n",
    "    correct_words[predictions != truth] = 0\n",
    "    correct_words[truth == ignore_idx] = 1\n",
    "\n",
    "    num_correct_words = correct_words.sum().item()\n",
    "    num_masked_words = len(truth[truth == ignore_idx])\n",
    "\n",
    "    return predictions.shape[0] * predictions.shape[1] - num_masked_words, num_correct_words - num_masked_words\n",
    "\n",
    "\n",
    "def measure_accuracy(network: torch.nn.Module,\n",
    "                    dataloader: DataLoader,\n",
    "                    device: str) -> float:\n",
    "    \"\"\"\n",
    "        Given a network, a dataloader and a device, iterates over the dataset and returns the network's accuracy.\n",
    "    \"\"\"\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for x_batch, y_batch in dataloader:\n",
    "        pred = network(x_batch.to(device))\n",
    "        local_total, local_correct = accuracy(pred.argmax(dim=-1), y_batch.to(device), ignore_idx=0)\n",
    "        correct+= local_correct\n",
    "        total+= local_total\n",
    "    return correct/total\n",
    "    \n",
    "\n",
    "def train_batch(network: torch.nn.Module,\n",
    "                X_batch: FloatTensor,\n",
    "                Y_batch: LongTensor,\n",
    "                loss_fn: Callable[[FloatTensor, FloatTensor], FloatTensor],  \n",
    "                optimizer: torch.optim.Optimizer) -> float:\n",
    "    \n",
    "    network.train()\n",
    "    prediction_batch = network(X_batch)  # forward pass\n",
    "    prediction_batch_reshaped = prediction_batch.view(prediction_batch.shape[0]*prediction_batch.shape[1], prediction_batch.shape[2])\n",
    "    Y_batch_reshaped = Y_batch.view(Y_batch.shape[0]*Y_batch.shape[1])\n",
    "    batch_loss = loss_fn(prediction_batch_reshaped, Y_batch_reshaped)  # loss calculation\n",
    "    batch_loss.backward()  # gradient computation\n",
    "    optimizer.step()  # back-propagation\n",
    "    optimizer.zero_grad()  # gradient reset\n",
    "    return batch_loss.item()\n",
    "\n",
    "def train_epoch(network: torch.nn.Module, \n",
    "                dataloader: DataLoader,\n",
    "                loss_fn: Callable[[FloatTensor, FloatTensor], FloatTensor],\n",
    "                optimizer: torch.optim.Optimizer, \n",
    "                device: str) -> float:\n",
    "    \n",
    "    loss = 0.\n",
    "    for i, (x_batch, y_batch) in enumerate(dataloader):\n",
    "        loss += train_batch(network=network, X_batch=x_batch, Y_batch=y_batch, loss_fn=loss_fn, optimizer=optimizer)\n",
    "    loss /= (i+1) # divide loss by number of batches for consistency \n",
    "    return loss\n",
    "\n",
    "def eval_batch(network: torch.nn.Module,\n",
    "                X_batch: FloatTensor,\n",
    "                Y_batch: LongTensor,\n",
    "                loss_fn: Callable[[FloatTensor, LongTensor], FloatTensor]) -> float:\n",
    "    \n",
    "    network.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        prediction_batch = network(X_batch)  # forward pass\n",
    "        prediction_batch_reshaped = prediction_batch.view(prediction_batch.shape[0]*prediction_batch.shape[1], prediction_batch.shape[2])\n",
    "        Y_batch_reshaped = Y_batch.view(Y_batch.shape[0]*Y_batch.shape[1])\n",
    "        batch_loss = loss_fn(prediction_batch_reshaped, Y_batch_reshaped)  # loss calculation\n",
    "        return batch_loss.item()\n",
    "\n",
    "def eval_epoch(network: torch.nn.Module, \n",
    "                # a list of data points x\n",
    "                dataloader: DataLoader,\n",
    "                loss_fn: Callable[[FloatTensor, LongTensor], FloatTensor],\n",
    "                device: str) -> float:\n",
    "    \n",
    "    loss = 0.\n",
    "    for i, (x_batch, y_batch) in enumerate(dataloader):\n",
    "        loss += eval_batch(network, x_batch, y_batch, loss_fn)\n",
    "    loss /= (i+1) # divide loss by number of batches for consistency \n",
    "        \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assignment 2.6: SRN POS tagging\n",
    "Define a simple recurrent network, with input size compatible with the vector dimensionality, output size compatible with the number of output classes (the number of different POS tags + 1) and a hidden size of your own choice. What is a reasonable choice?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a) Why do we need to add 1 to the number of output classes?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because the padding added 0 values to the ends of sequences, an additional output is required to differentiate the padded values from the original sequence entries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b) Implementation\n",
    "\n",
    "Use `\"tanh\"` as your hidden layer activation, and choose **an appropriate combination of output activation and loss function** (consider the task at hand, and refer to the documentation if in doubt- refer to tutorial as well!).\n",
    "\n",
    "Then instantiate an optimizer over your network, and train it for a number of epochs, measuring and printing all metrics in the process (train and validation loss and accuracy).\n",
    "\n",
    "_Hint_: Use `measure_accuracy` (defined earlier) to obtain accuracy.\n",
    "\n",
    "Plot the loss curves over the training process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "I = 300\n",
    "H = 150\n",
    "O = len(pos_to_int) + 1\n",
    "srn = fastSRN(I,H,O, 'tanh', torch.nn.LogSoftmax(dim=2), 'cpu')\n",
    "opt = torch.optim.Adam(srn.parameters(), lr=0.001)\n",
    "loss_fn = torch.nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following code was used to tune the network parameters\n",
    "\n",
    "import time\n",
    "device = 'cpu'\n",
    "NUM_EPOCHS = 10\n",
    "\n",
    "# train_losses = []\n",
    "# val_losses = []\n",
    "# train_accs = []\n",
    "# val_accs = []\n",
    "\n",
    "# start_time = time.time()\n",
    "# for t in range(NUM_EPOCHS):\n",
    "#     train_loss = train_epoch(srn, train_dataloader, optimizer=opt, loss_fn=loss_fn, device=device)\n",
    "#     val_loss = eval_epoch(srn, val_dataloader, loss_fn, device=device)\n",
    "#     train_acc = measure_accuracy(srn, train_dataloader, device=device)\n",
    "#     val_acc = measure_accuracy(srn, val_dataloader, device=device)\n",
    "    \n",
    "#     print('Epoch {}'.format(t))\n",
    "#     print(' Training Loss: {}'.format(train_loss))\n",
    "#     print(' Validation Loss: {}'.format(val_loss))\n",
    "#     print(' Training Accuracy: {}'.format(train_acc))\n",
    "#     print(' Validation Accuracy: {}'.format(val_acc))\n",
    "#     print('Elapsed time: ', time.time() - start_time)\n",
    "    \n",
    "#     train_losses.append(train_loss)\n",
    "#     val_losses.append(val_loss)\n",
    "#     train_accs.append(train_acc)\n",
    "#     val_accs.append(val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      " Training Loss: 0.3546352991501227\n",
      " Test Loss: 0.1426519439758166\n",
      " Training Accuracy: 0.9154456791229799\n",
      " Test Accuracy: 0.9143974817395556\n",
      "Epoch 1\n",
      " Training Loss: 0.12127474236567289\n",
      " Test Loss: 0.11183111102360746\n",
      " Training Accuracy: 0.9316564357618664\n",
      " Test Accuracy: 0.9296476269062681\n",
      "Epoch 2\n",
      " Training Loss: 0.10030973400698592\n",
      " Test Loss: 0.10012673157388749\n",
      " Training Accuracy: 0.9400147862711713\n",
      " Test Accuracy: 0.9354542954066196\n",
      "Epoch 3\n",
      " Training Loss: 0.08887174453660353\n",
      " Test Loss: 0.0945266394511513\n",
      " Training Accuracy: 0.9440156674731905\n",
      " Test Accuracy: 0.9379908926988784\n",
      "Epoch 4\n",
      " Training Loss: 0.08179662514798688\n",
      " Test Loss: 0.089513817154195\n",
      " Training Accuracy: 0.9487166562117274\n",
      " Test Accuracy: 0.9409553497753737\n",
      "Epoch 5\n",
      " Training Loss: 0.07635898741566582\n",
      " Test Loss: 0.08796814667141956\n",
      " Training Accuracy: 0.9519539534605849\n",
      " Test Accuracy: 0.9427584731517985\n",
      "Epoch 6\n",
      " Training Loss: 0.0714244995142845\n",
      " Test Loss: 0.08570860366782417\n",
      " Training Accuracy: 0.9547338471189175\n",
      " Test Accuracy: 0.9422389291280829\n",
      "Epoch 7\n",
      " Training Loss: 0.0673307392277465\n",
      " Test Loss: 0.08515724531658318\n",
      " Training Accuracy: 0.9569704573289124\n",
      " Test Accuracy: 0.9433391400018337\n",
      "Epoch 8\n",
      " Training Loss: 0.06410860004803992\n",
      " Test Loss: 0.08393108196880507\n",
      " Training Accuracy: 0.9586432476028318\n",
      " Test Accuracy: 0.9426973503254791\n",
      "Epoch 9\n",
      " Training Loss: 0.061529781360993324\n",
      " Test Loss: 0.08439680545226387\n",
      " Training Accuracy: 0.9602450936463841\n",
      " Test Accuracy: 0.9435530698939519\n"
     ]
    }
   ],
   "source": [
    "# after having tuned the parameters the final accuracy is calculated on the test set\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "train_accs = []\n",
    "test_accs = []\n",
    "\n",
    "for t in range(NUM_EPOCHS):\n",
    "    train_loss = train_epoch(srn, train_dataloader, optimizer=opt, loss_fn=loss_fn, device=device)\n",
    "    test_loss = eval_epoch(srn, test_dataloader, loss_fn, device=device)\n",
    "    train_acc = measure_accuracy(srn, train_dataloader, device=device)\n",
    "    test_acc = measure_accuracy(srn, test_dataloader, device=device)\n",
    "    \n",
    "    print('Epoch {}'.format(t))\n",
    "    print(' Training Loss: {}'.format(train_loss))\n",
    "    print(' Test Loss: {}'.format(test_loss))\n",
    "    print(' Training Accuracy: {}'.format(train_acc))\n",
    "    print(' Test Accuracy: {}'.format(test_acc))\n",
    "    \n",
    "    train_losses.append(train_loss)\n",
    "    test_losses.append(test_loss)\n",
    "    train_accs.append(train_acc)\n",
    "    test_accs.append(test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x147fc02d320>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting of the accuracy\n",
    "\n",
    "# naming the x axis \n",
    "plt.xlabel('epoch') \n",
    "# naming the y axis \n",
    "plt.ylabel('accuracy')\n",
    "plt.plot(range(1, NUM_EPOCHS + 1), train_accs, label = 'training accuracy')\n",
    "plt.plot(range(1, NUM_EPOCHS + 1), test_accs, label = 'test accuracy')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x147fd118f60>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting of the loss\n",
    "\n",
    "# naming the x axis \n",
    "plt.xlabel('epoch') \n",
    "# naming the y axis \n",
    "plt.ylabel('loss')\n",
    "plt.plot(range(1, NUM_EPOCHS + 1), train_losses, label = 'training loss')\n",
    "plt.plot(range(1, NUM_EPOCHS + 1), test_losses, label = 'test loss')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The test accuracy on this task should be well over 90%. If you are getting an accuracy much below this, play with your hyperparameters and try to improve. \n",
    "\n",
    "#### c) What is your final accuracy?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "94.2%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### d) A little error analysis\n",
    "Minimally, find a few instances of sentences with wrong tags. Can you say why these mistakes are made?\n",
    "Optionally, feel free is do a full error analysis. What are the most commonly confused tags for an English POS tagger?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regular TV series ratings have slumped in the past five years , and premiering new shows is a crap shoot , Mr. Pilson says .\n",
      "\n",
      "JJ  NN  NN  NNS  VBP  VBN  IN  DT  JJ  CD  NNS  ,  CC  VBG  JJ  NNS  VBZ  DT  NN  NN  ,  NNP  NNP  VBZ  .\n",
      "\n",
      "JJ  NNP  NNP  NNS  VBP  VBD  IN  DT  JJ  CD  NNS  ,  CC  VBG  NNP  VBZ  VBZ  DT  NN  PRP  ,  NNP  NNP  VBZ  .  \n",
      "\n",
      "\n",
      "\n",
      "But Mr. Zoeller also acknowledges that consultants can be very effective .\n",
      "\n",
      "CC  NNP  NNP  RB  VBZ  IN  NNS  MD  VB  RB  JJ  .\n",
      "\n",
      "CC  NNP  NNP  RB  VBZ  DT  NNS  MD  VB  RB  JJ  .  \n",
      "\n",
      "\n",
      "\n",
      "Sen. Dole also said he hoped for unanimous support for a resolution he plans to offer tomorrow denouncing the Nicaraguan leader .\n",
      "\n",
      "NNP  NNP  RB  VBD  PRP  VBD  IN  JJ  NN  IN  DT  NN  PRP  VBZ  TO  VB  NN  VBG  DT  JJ  NN  .\n",
      "\n",
      "NNP  NNP  RB  VBD  PRP  VBD  IN  JJ  NN  IN  DT  NNP  PRP  NNS  TO  NN  NN  VBG  DT  JJ  NN  .  \n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "int_to_pos = [(v, k) for k, v in pos_to_int.items()]\n",
    "int_to_pos.insert(0, (0, 'PAD'))\n",
    "int_to_pos.sort()\n",
    "int_to_pos = dict(int_to_pos)\n",
    "\n",
    "# indexes = random.sample(range(len(sentences)), 5)  # used to find sentences\n",
    "indexes = list([11823, 14963, 6589])\n",
    "\n",
    "for idx in indexes:\n",
    "    test_sentence = sentences[idx]\n",
    "    true_tags = postags[idx]\n",
    "\n",
    "    test_doc = nlp(test_sentence)  # the processed sentence\n",
    "    test_vectors = list(map(lambda x: x.vector, test_doc))  # its vectors\n",
    "    test_vectors = torch.FloatTensor(test_vectors).unsqueeze(0)\n",
    "\n",
    "    values = srn(test_vectors).squeeze(0)\n",
    "    values_list = list(map(lambda x: x.argmax(dim=0).item(), values))\n",
    "\n",
    "    print(test_sentence)\n",
    "    print()\n",
    "    print(*true_tags, sep = \"  \")\n",
    "    print()\n",
    "    for value, comp in zip(values_list, true_tags):\n",
    "        pos = int_to_pos.get(value)\n",
    "        if pos != comp:\n",
    "            print(pos, \" \", end = '')\n",
    "        else:\n",
    "            print(pos, \" \", end = '')\n",
    "    print('\\n' * 3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code above gives a few sentences, their tags as given by the database, and the tags generated by the RNS made for this assignment.\n",
    "\n",
    "In multiple cases the RNS has issues correctly classifying different forms of nouns. For example, in the first sentence, the word 'series', and in the last sentence the word 'resolution' is classified as a proper noun instead of a singular common noun.\n",
    "This is quite understandable as nouns and proper nouns are used almost identically in sentence structure. The most significant difference is the fact that proper nouns are always capitalized, but because common nouns are also capitalized when at the beginning of a sentence this can be hard to learn.\n",
    "\n",
    "Similar mistakes are made in the first sentence, where verbs being falsely classified as different kinds of verbs. The word 'slumped' is tagged as a past tense verb, instead of a past participle verb. The time (past tense) was properly identified, but the nuanced differences between these types of words are hard to catch.\n",
    "\n",
    "There are also a few examples where nouns are classified as verbs and vice-versa. Examples of these are the words 'shows' and 'plans'. All of these words can be either verbs or nouns depending on the context. While a RNS should be able to find some of these differences due to being more aware of temporal relationships of words in sentences, this does not seem to work perfectly.\n",
    "\n",
    "The interpretations of temporal relationships could also lead to some errors. In the first sentence, the word 'new' gets tagged as a proper noun instead of as an adjective. This is likely because it is more common to have some type of noun right after a verb. In the second sentence, the word 'that' is tagged as a determiner instead of as a preposition. This is likely because often after a connective type of word a determiner is given to describe the relation between a verb and what comes next, instead of a preposition.\n",
    "\n",
    "The misidentification of 'premiering', classified as an adjective, is hard to explain, but coherent with the classification of 'new' as a noun and 'shows' as a verb.\n",
    "\n",
    "The classification of 'shoot' as a personal pronoun cannot be explained in linguistic terms."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
